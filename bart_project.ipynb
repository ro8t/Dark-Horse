{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make BART Great Again\n",
    "# Dependencies\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "# Personal dependencies\n",
    "from config import nyc_track_length\n",
    "#from config import nyc_avg_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART has 45 stations.\n"
     ]
    }
   ],
   "source": [
    "# 2015 BART station data\n",
    "bart_station_api_url = 'https://data.bart.gov/api/3/action/datastore_search'\n",
    "all_stations = '?resource_id=48bee8d8-6106-4215-a937-31d71ee09f0c'\n",
    "limit_search = '&limit=5'\n",
    "bart_station_json = requests.get(bart_station_api_url + all_stations).json()\n",
    "num_bart_stations = len(bart_station_json['result']['records'])\n",
    "print(f'BART has {num_bart_stations} stations.')\n",
    "#print(f'BART has {bart_line_tot} lines.')\n",
    "#pprint(bart_station_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sao Paulo metro has 79 stations and a total of 6 lines.\n",
      "Sao Paulo metro lines: [\"['azul']\", \"['vermelha']\", \"['lilas']\", \"['verde']\", \"['amarela']\", \"['prata']\"]\n"
     ]
    }
   ],
   "source": [
    "# Sao Paulo metro data\n",
    "# Bring csv data into pandas dataframe\n",
    "sp_metro_file = os.path.join('sao-paulo-metro-data', 'metrosp_stations_v2.csv')\n",
    "with open(sp_metro_file, newline='') as metro_holder:\n",
    "    sp_metro = csv.reader(metro_holder, delimiter=',')\n",
    "    sp_metro_headers = next(sp_metro)\n",
    "    sp_metro_data = pd.DataFrame([row for row in sp_metro])\n",
    "\n",
    "# Clean sp metro data\n",
    "sp_metro_data = sp_metro_data.rename(columns={0: sp_metro_headers[0],\n",
    "                                              1: sp_metro_headers[1],\n",
    "                                              2: sp_metro_headers[2],\n",
    "                                              3: sp_metro_headers[3],\n",
    "                                              4: sp_metro_headers[4],\n",
    "                                              5: sp_metro_headers[5]})\n",
    "sp_metro_data = sp_metro_data.drop(columns=['', 'station', 'lat', 'lon'])\n",
    "\n",
    "num_sp_stations = len(sp_metro_data['name'])\n",
    "\n",
    "sp_lines = list(sp_metro_data['line'].value_counts().index[:6])\n",
    "num_sp_lines = len(sp_lines)\n",
    "\n",
    "print(f'Sao Paulo metro has {num_sp_stations} stations and a total of {num_sp_lines} lines.')\n",
    "print(f'Sao Paulo metro lines: {sp_lines}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'millions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'millions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8752822d1f1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#nyc_metro_data2.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m#nyc_metro_data3.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mnyc_metro_data3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'millions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnyc_metro_data3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'millions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mnyc_metro_data3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#nyc_total_rider = nyc_metro_data3['million'].sum()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'millions'"
     ]
    }
   ],
   "source": [
    "#NYC subway data\n",
    "#bring csvs into pandas dataframes\n",
    "nyc_metro_file = os.path.join('nyc-metro-data', 'stops.csv')\n",
    "with open(nyc_metro_file, newline='') as metro_holder:\n",
    "    nyc_metro = csv.reader(metro_holder, delimiter=',')\n",
    "    nyc_metro_headers = next(nyc_metro)\n",
    "    nyc_metro_data = pd.DataFrame([row for row in nyc_metro])\n",
    "nyc_metro_file2 = os.path.join('nyc-metro-data', 'nyc-transit-subway-entrance-and-exit-data.csv')\n",
    "with open(nyc_metro_file2, newline='') as metro_holder2:\n",
    "    nyc_metro2 = csv.reader(metro_holder2, delimiter=',')\n",
    "    nyc_metro_headers2 = next(nyc_metro2)\n",
    "    nyc_metro_data2 = pd.DataFrame([row for row in nyc_metro2])\n",
    "nyc_metro_file3 = os.path.join('nyc-metro-data', '2017-station-entry-and-exit-figures.csv')\n",
    "with open(nyc_metro_file3, newline='') as metro_holder3:\n",
    "    nyc_metro3 = csv.reader(metro_holder3, delimiter=',')\n",
    "    nyc_metro_headers3 = next(nyc_metro3)\n",
    "    nyc_metro_data3 = pd.DataFrame([row for row in nyc_metro3])\n",
    "#cleaning nyc data\n",
    "nyc_metro_data = nyc_metro_data.rename(columns={0: nyc_metro_headers[0],\n",
    "                                              1: nyc_metro_headers[1],\n",
    "                                              2: nyc_metro_headers[2],\n",
    "                                              3: nyc_metro_headers[3],\n",
    "                                              4: nyc_metro_headers[4],\n",
    "                                              5: nyc_metro_headers[5],\n",
    "                                              6: nyc_metro_headers[6],\n",
    "                                              7: nyc_metro_headers[7],\n",
    "                                              8: nyc_metro_headers[8],\n",
    "                                              9: nyc_metro_headers[9]})\n",
    "nyc_metro_data2 = nyc_metro_data2[[0, 1, 2, 3, 4]]\n",
    "nyc_metro_data2 = nyc_metro_data2.rename(columns={0: nyc_metro_headers2[0],\n",
    "                                              1: nyc_metro_headers2[1],\n",
    "                                              2: nyc_metro_headers2[2],\n",
    "                                              3: nyc_metro_headers2[3],\n",
    "                                              4: nyc_metro_headers2[4]})\n",
    "nyc_metro_data = nyc_metro_data.drop(columns=['stop_code', 'stop_desc', 'zone_id', 'stop_url'])\n",
    "nyc_metro_data3 = nyc_metro_data3.rename(columns={0: nyc_metro_headers3[0],\n",
    "                                              1: nyc_metro_headers3[1],\n",
    "                                              2: nyc_metro_headers3[2],\n",
    "                                              3: nyc_metro_headers3[3],\n",
    "                                              4: nyc_metro_headers3[4],\n",
    "                                              5: nyc_metro_headers3[5],\n",
    "                                              6: nyc_metro_headers3[6],\n",
    "                                              7: nyc_metro_headers3[7],\n",
    "                                              8: nyc_metro_headers3[8],\n",
    "                                              9: nyc_metro_headers3[9],\n",
    "                                              10: nyc_metro_headers3[10]})\n",
    "#nyc_metro_data2.head()\n",
    "#nyc_metro_data3.head()\n",
    "#nyc_metro_data3['millions'] = pd.to_numeric(nyc_metro_data3['millions'], errors='coerce')\n",
    "#nyc_total_rider = nyc_metro_data3['million'].sum()\n",
    "#print(nyc_total_rider)\n",
    "nyc_station_total = len(nyc_metro_data.stop_name.value_counts())\n",
    "nyc_line_total = len(nyc_metro_data2.Line.value_counts())\n",
    "print(f'The NYC subway has {nyc_station_total} stations.')\n",
    "print(f'The NYC subway has {nyc_line_total} lines.')\n",
    "print(f'The NYC subway has {nyc_track_length} miles of track.')\n",
    "print(f'The NYC subway has an average fare of ${nyc_avg_fare}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#London tube data\n",
    "#call api for data\n",
    "tube_station_url = \"https://api.tfl.gov.uk/Stoppoint/940GZZLUCHX/FareTo/940GZZLUBST\"\n",
    "tube_station_data = requests.get(tube_station_url).json()\n",
    "#pprint(tube_station_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
